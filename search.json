[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "InSAR Book",
    "section": "",
    "text": "1 Introducción\nEste libro tiene por por objetivo ir documentando y comunicando los avances en el repoceso de replicar el flujo de trabajado de corrección de imagenes tipo Radar de Apertura Sintética (SAR) en python en el proceso de interferometría (InSAR).\nLos datos SAR también pueden permitir un método de análisis denominado interferometría o InSAR. InSAR utiliza la información de fase registrada por el sensor para medir la distancia del sensor al objetivo. Cuando se realizan al menos dos observaciones del mismo objetivo, la distancia, con información geométrica adicional del sensor, puede utilizarse para medir los cambios en la topografía de la superficie terrestre. Estas mediciones son muy precisas (hasta el nivel de centímetros) y pueden utilizarse para identificar zonas de deformación debidas a fenómenos como erupciones volcánicas y terremotos.\n\n\n\nInterferogram from Sentinel-1 SAR data acquired 2018/02/17 and 02/05 shows earthquake fault slip on a subduction thrust fault causing up to 40 cm of uplift of the ground surface. The motion has been contoured with 9 cm color contours, also known as fringes. Credit: NASA Disasters Program.\n\n\nPreguntas:\n\nProblema\nObjetivos\nDefinición de “Bursts”\nDefinición de “GA”\nDefinición de “SLC”\n\nTODO:\n\nDocumentación inSAR\nDocumentar las correcciones\nInvestigar\n\nCo-registration\n“SBAS” network\nUnsupervised algorithm like snaphu of MCF\nPixel-wise process\n\nEntender el problema\nDefinir Objetivos\nCrear Pipeline con imágenes\nCrear Esquema de tareas\nPreparar Glosario\nInvestigar de sobre los softwares\nVariables book (productos satelitales, softwares, etc)"
  },
  {
    "objectID": "interf.html#introduction",
    "href": "interf.html#introduction",
    "title": "4  Marco Conceptual",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nAunque la mayoría de los científicos que utilizan la teledetección están familiarizados con las imágenes ópticas pasivas del Landsat del Servicio Geológico de Estados Unidos, el espectrorradiómetro de imágenes de resolución moderada (MODIS) de la NASA y el Sentinel-2 de la Agencia Espacial Europea, como por ejemplo, hay otro tipo de datos de teledetección que está llamando la atención: El radar de apertura sintética o SAR. El SAR es un tipo de adquisición de datos activa en la que un sensor produce su propia energía y registra la cantidad de energía reflejada tras interactuar con la Tierra. Mientras que las imágenes ópticas son similares a la interpretación de una fotografía, los datos SAR requieren una forma diferente de pensar, ya que la señal responde a las características de la superficie, como la estructura y la humedad."
  },
  {
    "objectID": "interf.html#radar-de-apertura-sintética",
    "href": "interf.html#radar-de-apertura-sintética",
    "title": "4  Marco Conceptual",
    "section": "4.2 Radar de Apertura Sintética:",
    "text": "4.2 Radar de Apertura Sintética:\nLa resolución espacial de los datos de radar está directamente relacionada con la relación entre la longitud de onda del sensor y la longitud de la antena del sensor. Para una longitud de onda dada, cuanto más larga sea la antena, mayor será la resolución espacial. Desde un satélite en el espacio que opera a una longitud de onda de unos 5 cm (radar de banda C), para obtener una resolución espacial de 10 m, se necesitaría una antena de radar de unos 4.250 m de longitud.\nUna antena de ese tamaño no es práctica para un sensor de satélite en el espacio. Por eso, científicos e ingenieros han ideado una ingeniosa solución: la apertura sintética. En este concepto, una secuencia de adquisiciones de una antena más corta se combinan para simular una antena mucho mayor, proporcionando así datos de mayor resolución (Figure 4.1)\n\n\n\nFigure 4.1: Geometría de las observaciones utilizadas para formar la apertura sintética para el objetivo P en la posición a lo largo de la pista x = 0. Crédito: NASA SAR Handbook"
  },
  {
    "objectID": "interf.html#frecuencia-y-longitud-de-onda",
    "href": "interf.html#frecuencia-y-longitud-de-onda",
    "title": "4  Marco Conceptual",
    "section": "4.3 Frecuencia y longitud de onda",
    "text": "4.3 Frecuencia y longitud de onda\nLos sensores ópticos, como el Operational Land Imager (OLI) de Landsat y el Multispectral Instrument (MSI) de Sentinel-2, recogen datos en las porciones visible, infrarroja cercana e infrarroja de onda corta del espectro electromagnético. Los sensores de radar utilizan longitudes de onda más largas a escala de centímetros a metros, lo que les confiere propiedades especiales, como la capacidad de ver a través de las nubes (Figure 4.2).\n\n\n\nFigure 4.2: El espectro electromagnético con las bandas de microondas en recuadro\n\n\nLas diferentes longitudes de onda del SAR suelen denominarse bandas, con designaciones de letras como X, C, L y P. En la tabla siguiente se indica la banda con la frecuencia asociada, la longitud de onda y la aplicación típica para esa banda.\n\n\n\n\n\nBand\nFrequency\nWavelength\nTypical.Application\n\n\n\n\nKa\n27–40 GHz\n1.1–0.8 cm\nRarely used for SAR (airport surveillance)\n\n\nK\n18–27 GHz\n1.7–1.1 cm\nrarely used (H2O absorption)\n\n\nKu\n12–18 GHz\n2.4–1.7 cm\nrarely used for SAR (satellite altimetry)\n\n\nX\n8–12 GHz\n3.8–2.4 cm\nHigh resolution SAR (urban monitoring,; ice and snow, little penetration into vegetation cover; fast coherence decay in vegetated areas)\n\n\nC\n4–8 GHz\n7.5–3.8 cm\nSAR Workhorse (global mapping; change detection; monitoring of areas with low to moderate penetration; higher coherence); ice, ocean maritime navigation\n\n\nS\n2–4 GHz\n15–7.5 cm\nLittle but increasing use for SAR-based Earth observation; agriculture monitoring (NISAR will carry an S-band channel; expends C-band applications to higher vegetation density)\n\n\nL\n1–2 GHz\n30–15 cm\nMedium resolution SAR (geophysical monitoring; biomass and vegetation mapping; high penetration, InSAR)\n\n\nP\n0.3–1 GHz\n100–30 cm\nBiomass. First p-band spaceborne SAR will be launched ~2020; vegetation mapping and assessment. Experimental SAR.\n\n\n\n\n\n\n\n\n\n\nEjemplos de imágenes SAR en frecuencias de banda C, L y P del sistema AIRSAR sobre bosques tropicales a lo largo del río Ja en Papúa Nueva Guinea que muestran las diferencias de penetración y los impactos de la estructura forestal y la humedad subyacente en las imágenes SAR de falso color compuesto (HH, HV, VV).\n\n\nLa longitud de onda es una característica importante a tener en cuenta cuando se trabaja con SAR, ya que determina cómo interactúa la señal del radar con la superficie y hasta dónde puede penetrar una señal en un medio. Por ejemplo, un radar de banda X, que funciona a una longitud de onda de unos 3 cm, tiene muy poca capacidad para penetrar en el bosque de hoja ancha, por lo que interactúa principalmente con las hojas de la parte superior de la copa de los árboles. En cambio, una señal de banda L tiene una longitud de onda de unos 23 cm, con lo que consigue una mayor penetración en el bosque y permite una mayor interacción entre la señal del radar y las grandes ramas y troncos de los árboles. La longitud de onda no sólo influye en la profundidad de penetración en los bosques, sino también en otros tipos de cobertura terrestre, como el suelo y el hielo.\nPor ejemplo, científicos y arqueólogos están utilizando datos SAR para ayudar a “descubrir” ciudades perdidas e infraestructuras de tipo urbano ocultas a lo largo del tiempo por la densa vegetación o las arenas del desierto. Para más información sobre el uso del SAR en arqueología espacial, véanse las publicaciones del Observatorio de la Tierra de la NASA Peering through the Sands of Time y Secrets beneath the Sand."
  },
  {
    "objectID": "interf.html#mecanismos-de-polarización-y-dispersión",
    "href": "interf.html#mecanismos-de-polarización-y-dispersión",
    "title": "4  Marco Conceptual",
    "section": "4.4 Mecanismos de polarización y dispersión",
    "text": "4.4 Mecanismos de polarización y dispersión\nEl radar también puede recoger señales en diferentes polarizaciones, controlando la polarización analizada tanto en el trayecto de transmisión como en el de recepción. La polarización se refiere a la orientación del plano en el que oscila la onda electromagnética transmitida. Aunque la orientación puede producirse en cualquier ángulo, los sensores SAR suelen transmitir con polarización lineal. La polarización horizontal se indica con la letra H, y la vertical con la V.\nLa ventaja de los sensores de radar es que la polarización de la señal puede controlarse con precisión tanto en la transmisión como en la recepción. Las señales emitidas en polarización vertical (V) y recibidas en polarización horizontal (H) se indicarían con una VH. Alternativamente, una señal emitida en horizontal (H) y recibida en horizontal (H) se indicaría con HH, y así sucesivamente (Figure 4.3).\n\n\n\nFigure 4.3: Ondas electromagnéticas irradiadas al paisaje en orientaciones horizontal y vertical que proporcionan diferentes mediciones de polarización lineal.\n\n\nExaminando la intensidad de la señal de estas polarizaciones diferentes aporta información sobre la estructura de la superficie de la imagen, basada en los siguientes tipos de dispersión: superficie rugosa, volumen y doble rebote (Figure 4.4).\n\n\n\nFigure 4.4: La fuerte dispersión en HH indica un predominio de la dispersión de doble rebote (por ejemplo, vegetación con tallos, estructuras hechas por el hombre), mientras que la fuerte VV se relaciona con la dispersión de superficies rugosas (por ejemplo, suelo desnudo, agua), y las variaciones espaciales en la polarización dual indican la distribución de los dispersores de volumen (por ejemplo, vegetación y tipos de suelo de alta penetración como arena u otros suelos porosos secos). Créditos: NASA SAR Handbook.\n\n\n\nLa dispersión de la superficie rugosa, como la causada por el suelo desnudo o el agua, es más sensible a la dispersión VV.\nLa dispersión de volumen, por ejemplo, causada por las hojas y ramas de un bosque, es más sensible a datos de polarización cruzada como VH o HV.\nEl último tipo de dispersión, el doble rebote, está causado por edificios, troncos de árboles o vegetación inundada y es más sensible a una señal polarizada HH.\n\nEs importante señalar que la cantidad de señal atribuida a los diferentes tipos de dispersión puede cambiar en función de la longitud de onda, ya que ésta modifica la profundidad de penetración de la señal. Por ejemplo, una señal de banda C sólo penetra en las capas superiores del dosel de un bosque y, por lo tanto, experimentará principalmente dispersión de rugosidad mezclada con una cantidad limitada de dispersión de volumen. Sin embargo, una señal de banda L o de banda P tendrá una penetración mucho más profunda y, por lo tanto, experimentará una dispersión de volumen fuertemente aumentada, así como cantidades crecientes de dispersión de doble rebote causada por el tronco del árbol (Figure 4.5).\n\n\n\nFigure 4.5: Sensibilidad de las mediciones SAR a la estructura del bosque y a la penetración en el dosel en diferentes longitudes de onda utilizadas para las observaciones por teledetección de la superficie terrestre desde el aire o el espacio. Credit: NASA SAR Handbook."
  },
  {
    "objectID": "interf.html#interferometría",
    "href": "interf.html#interferometría",
    "title": "4  Marco Conceptual",
    "section": "4.5 Interferometría",
    "text": "4.5 Interferometría\nLos datos SAR también pueden permitir un método de análisis denominado interferometría o InSAR. InSAR utiliza la información de fase registrada por el sensor para medir la distancia del sensor al objetivo. Cuando se realizan al menos dos observaciones del mismo objetivo, la distancia, con información geométrica adicional del sensor, puede utilizarse para medir los cambios en la topografía de la superficie terrestre. Estas mediciones son muy precisas (hasta el nivel de centímetros) y pueden utilizarse para identificar zonas de deformación debidas a fenómenos como erupciones volcánicas y terremotos.\n\n\n\nEl interferograma de los datos SAR de Sentinel-1 adquiridos el 17/02/2018 y el 05/02 muestra el deslizamiento de la falla sísmica en una falla de empuje de subducción que causa hasta 40 cm de elevación de la superficie del suelo. El movimiento se ha contorneado con contornos de color de 9 cm, también conocidos como franjas. Crédito: NASA Disasters Program.\n\n\nUna señal SAR contiene información de amplitud y fase. La amplitud es la fuerza de la respuesta del radar y la fase es la fracción de un ciclo completo de onda sinusoidal (una sola longitud de onda SAR). La fase de la imagen SAR viene determinada principalmente por la distancia entre la antena del satélite y los objetivos terrestres.\nEl SAR interferométrico (InSAR) explota la diferencia de fase entre dos observaciones SAR radar complejas de la misma zona, tomadas desde posiciones de sensor ligeramente diferentes, y extrae información de distancia sobre el terreno terrestre.\nCombinando la fase de estas dos imágenes tras el coregistro, se puede generar un interferograma en el que la fase está altamente correlacionada con la topografía del terreno y se pueden cartografiar los patrones de deformación. Si se elimina de los interferogramas el desplazamiento de fase relacionado con la topografía, la diferencia entre los productos resultantes mostrará los patrones de deformación de la superficie ocurridos entre las dos fechas de adquisición. Esta metodología se denomina interferometría diferencial (DInSAR)."
  },
  {
    "objectID": "interf.html#referencias",
    "href": "interf.html#referencias",
    "title": "4  Marco Conceptual",
    "section": "4.6 Referencias:",
    "text": "4.6 Referencias:\n\nhttps://www.earthdata.nasa.gov/learn/backgrounders/what-is-sar\nhttps://gis1.servirglobal.net/TrainingMaterials/SAR/ch5.pdf"
  },
  {
    "objectID": "pipeline.html#processing-sar",
    "href": "pipeline.html#processing-sar",
    "title": "5  Pipeline",
    "section": "5.1 Processing SAR",
    "text": "5.1 Processing SAR\n\n5.1.1 Data Access\nNeed SLC products Source ASF, CopHub, etc.\n\n\n5.1.2 Data organisation\nDelivered S1 SLC scenes do not consistently have the same coverage. Either do further processing at the “burst” level, or form new scenes from sets of bursts). The latter approach was used at GA.\n\n\n5.1.3 Co-registration of reference SLC to DEM\nThis mapping is used later for interferogram geocoding\n\n\n5.1.4 Co-registration of other SLCs to reference\nThe co-registration of each S1 image needs to be better than 1/1000th of a pixel to avoid burst discontinuities. GA implemented a tree network structure to apply co-registrations and avoid propagating mis-registration in a large multi-year stack of 12 day images.\n\n\n5.1.5 Interferogram formation\nTypically done with an “SBAS” network where every SAR image is used to form multiple interferograms for redundancy of information\n\n\n5.1.6 Interferogram unwrapping\nConvert fringes to continuous phase field using unsupervised algorithm like snaphu of MCF. These are good for automation but they do make mistakes (unwrapping errors)\n\n\n5.1.7 Geocoding\nConvert products (interferograms, coherence, backscatter) from radar to geographic geometry"
  },
  {
    "objectID": "pipeline.html#time-series-processing",
    "href": "pipeline.html#time-series-processing",
    "title": "5  Pipeline",
    "section": "5.2 Time Series Processing",
    "text": "5.2 Time Series Processing\n\n5.2.1 Unwrapping check\nThrow out pixels that fail the check – removes unwrapping errors\n\n\n5.2.2 Orbital error removal\nModel long wavelength spatial trends and remove. Usually not that important for S1\n\n\n5.2.3 Atmospheric noise removal\nVarious approaches, best use external weather model data to generate a phase correction\n\n\n5.2.4 Network inversion for displacement time series\nPixel-wise process\n\n\n5.2.5 Network inversion for average displacement\nPixel-wise process for velocity"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Lazecký, Milan, Karsten Spaans, Pablo J. González, Yasser Maghsoudi, Yu\nMorishita, Fabien Albino, John Elliott, et al. 2020.\n“LiCSAR: An Automatic InSAR Tool for\nMeasuring and Monitoring Tectonic and Volcanic Activity.”\nRemote Sensing 12 (15): 2430. https://doi.org/10.3390/rs12152430.\n\n\nMorishita, Yu, Milan Lazecky, Tim Wright, Jonathan Weiss, John Elliott,\nand Andy Hooper. 2020. “LiCSBAS: An Open-Source\nInSAR Time Series Analysis Package Integrated with the\nLiCSAR Automated Sentinel-1 InSAR\nProcessor.” Remote Sensing 12 (3): 424. https://doi.org/10.3390/rs12030424."
  },
  {
    "objectID": "glosario.html",
    "href": "glosario.html",
    "title": "Appendix A — Glosario",
    "section": "",
    "text": "ASF\nCopernicus Hub\nSLC\nS1\nGA\nSBAS Network"
  },
  {
    "objectID": "softwares.html#insar-softwares",
    "href": "softwares.html#insar-softwares",
    "title": "Appendix B — Softwares",
    "section": "B.1 InSAR softwares",
    "text": "B.1 InSAR softwares\n\nSNAP:\n\nThe Sentinel Application Platform (SNAP) is a common architecture for all Sentinel Toolboxes. The software is developed by Brockmann Consult, Skywatch, Sensar and C-S. The SNAP architecture is ideal for Earth observation (EO) processing and analysis due to the following technological innovations: extensibility, portability, modular rich client platform, generic EO data abstraction, tiled memory management, and a graph processing framework. SNAP and the individual Sentinel Toolboxes support numerous sensors other than Sentinel sensors.\n\n\nhttp://www.gisandbeers.com/snap-analisis-imagenes-satelite-sentinel/\n\nGAMMA:\n\nThe GAMMA Software is a commercial software developed and maintained by GAMMA. We are dedicated to keep the software at a very advanced level. Through our R&D projects and the many contacts to highly competent SAR/InSAR/PSI specialists, we get valuable inputs to the software development activities. We regularly implement new functionality and adaptations to support new sensors and algorithms. Software licenses are in use world-wide supporting researchers, companies and public authorities in their daily work.\n\n\nThe GAMMA software supports the entire processing chain from Synthetic Aperture Radar (SAR) raw data to end products such as digital elevation models, displacement maps and land use maps. The GAMMA Software includes several Modules, each one consisting of documented, well structured code. The software is a toolbox providing a wide functionality to support the users in the setting up different processing tasks. Programs can be run individually on the command line or they can be called from scripts that permit running processing sequences in a more automated and efficient way.\nSoftware Modules:\n\nModular SAR Processor (MSP)\nInterferometry, Diff. Interferometry and Geocoding (ISP/DIFF&GEO)\nLand Application Tools (LAT)\nInterferometric Point Target Analysis (IPTA)\n\n\nGMTSAR:\n\nGMTSAR is an open source (GNU General Public License) InSAR processing system designed for users familiar with Generic Mapping Tools (GMT). The code is written in C and will compile on any computer where GMT and NETCDF are installed. The system has three main components:\n\n\n\na preprocessor for each satellite data type (ERS-1/2, Envisat, ALOS-1, TerraSAR-X, COSMOS-SkyMed, Radarsat-2, Sentinel-1A/B, and ALOS-2) to convert the native format and orbital information into a generic format;\nan InSAR processor to focus and align stacks of images, map topography into phase, and form the complex interferogram;\na postprocessor, mostly based on GMT, to filter the interferogram and construct interferometric products of phase, coherence, phase gradient, and line-of sight displacement in both radar and geographic coordinates;\n\nGMT is used to display all the products as pdf files and KML images for Google Earth. A set of shell scripts has been developed for standard 2-pass processing as well as geometric image alignment for stacking and time series. Users are welcome to contribute to this effort.\n\nISCE:\n\nThis is the Interferometric synthetic aperture radar Scientific Computing Environment (ISCE). Its initial development was funded by NASA’s Earth Science Technology Office (ESTO) under the Advanced Information Systems Technology (AIST) 2008 and is currently being funded under the NASA-ISRO SAR (NISAR) project.\n\n\nTHIS IS RESEARCH CODE PROVIDED TO YOU “AS IS” WITH NO WARRANTIES OF CORRECTNESS. USE AT YOUR OWN RISK.\nThis software is open source under the terms of the the Apache License. Its export classification is ‘EAR99 NLR’, which entails some restrictions and responsibilities. Please read the accompanying LICENSE.txt and LICENSE-2.0 files.\nISCE is a framework designed for the purpose of processing Interferometric Synthetic Aperture Radar (InSAR) data. The framework aspects of it have been designed as a general software development framework. It may have additional utility in a general sense for building other types of software packages. In its InSAR aspect ISCE supports data from many space-borne satellites and one air-borne platform. We continue to increase the number of sensors supported. At this time the sensors that are supported are the following: ALOS, ALOS2, COSMO_SKYMED, ENVISAT, ERS, KOMPSAT5, RADARSAT1, RADARSAT2, RISAT1, Sentinel1, TERRASARX, UAVSAR and SAOCOM1A."
  },
  {
    "objectID": "softwares.html#time-series-softwares",
    "href": "softwares.html#time-series-softwares",
    "title": "Appendix B — Softwares",
    "section": "B.2 Time series softwares",
    "text": "B.2 Time series softwares\n\nStaMPS:\n\nA software package to extract ground displacements from time series of synthetic aperture radar (SAR) acquisitions. The original version was developed at Stanford University but subsequent development has taken place at the University of Iceland, Delft University of Technology and the University of Leeds.The package incorporates persistent scatterer and small baseline methods plus an option to combine both approaches.\n\nPyRate:\n\nPyRate is a Python tool for estimating the average displacement rate (velocity) and cumulative displacement time-series of surface movements for every pixel in a stack of geocoded unwrapped interferograms generated by Interferometric Synthetic Aperture Radar (InSAR) processing. PyRate uses a “Small Baseline Subset” (SBAS) processing strategy and currently supports input data in the GAMMA or ROI_PAC software formats. Additionally, the European Space Agency SNAP software version 8 has a “PyRate export” capability that prepares SNAP output data in the GAMMA format for use with PyRate.\n\n\nThe PyRate project started in 2012 as a partial Python translation of “Pirate”, a Matlab tool developed by the University of Leeds and the Guangdong University of Technology.\nThe full PyRate documentation is available at http://geoscienceaustralia.github.io/PyRate\n\nMintPy:\n\nThe Miami INsar Time-series software in PYthon (MintPy as /mɪnt paɪ/) is an open-source package for Interferometric Synthetic Aperture Radar (InSAR) time series analysis. It reads the stack of interferograms (coregistered and unwrapped) in ISCE, ARIA, FRInGE, HyP3, GMTSAR, SNAP, GAMMA or ROI_PAC format, and produces three dimensional (2D in space and 1D in time) ground surface displacement in line-of-sight direction. It includes a routine time series analysis (smallbaselineApp.py) and some independent toolbox. This package was called PySAR before version 1.1.1. For version 1.1.2 and onward, we use MintPy instead. This is research code provided to you “as is” with NO WARRANTIES OF CORRECTNESS. Use at your own risk.\n\nLicSAR:\n\nFor each frame, the main LiCSAR outputs are stored in the ‘Products’ folder. As can be seen in Figure 1, all the generated interferometric pairs are located in the ‘Interferograms’ folder. The name of each interferometric pair shows the date of acquisitions in that pair. We are currently generating three interferograms per epoch. For the details of the LiCSAR methodology, the reader is referred to (Lazecký et al. 2020). In summary, once a new acquisition arrives, it is being logically decomposed into pre-defined burst units and registered in the LiCSInfo database that handles burst and frame definitions. Images including bursts that form a given frame are extracted and merged into frame images. These are coregistered towards a primary frame image (a master image) that was set during the initialization of a frame, beforehand. The coregistration process includes the spectral diversity and other necessary corrections. Once coregistered, the interferograms are formed by combining the new image with three chronologically previous ones. This way is suitable for interpretation and for further use of the interferograms in multitemporal InSAR processing methods based on small baselines strategy (e.g. NSBAS approach currently implemented into custom LiCSBAS chain (Morishita et al. 2020)). The interferogram unwrapping is performed using optimized SNAPHU approach. All the LiCSAR products are multilooked by factors of 5 in the range and 20 in the azimuth directions to achieve a resolution of around 100×100 m per pixel.\n\n\n\n\n\n\nLazecký, Milan, Karsten Spaans, Pablo J. González, Yasser Maghsoudi, Yu Morishita, Fabien Albino, John Elliott, et al. 2020. “LiCSAR: An Automatic InSAR Tool for Measuring and Monitoring Tectonic and Volcanic Activity.” Remote Sensing 12 (15): 2430. https://doi.org/10.3390/rs12152430.\n\n\nMorishita, Yu, Milan Lazecky, Tim Wright, Jonathan Weiss, John Elliott, and Andy Hooper. 2020. “LiCSBAS: An Open-Source InSAR Time Series Analysis Package Integrated with the LiCSAR Automated Sentinel-1 InSAR Processor.” Remote Sensing 12 (3): 424. https://doi.org/10.3390/rs12030424."
  }
]