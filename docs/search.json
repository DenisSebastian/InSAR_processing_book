[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "InSAR Book",
    "section": "",
    "text": "1 Introducción\nEste libro tiene por por objetivo ir documentando y comunicando los avances en el repoceso de replicar el flujo de trabajado de corrección de imagenes tipo Radar de Apertura Sintética (SAR) en python en el proceso de interferometría.\nPreguntas:\n\nProblema\nObjetivos\nDefinición de “Bursts”\nDefinición de “GA”\nDefinición de “SLC”\n\nTODO:\n\nDocumentación inSAR\nDocumentar las correcciones\nInvestigar\n\nCo-registration\n“SBAS” network\nUnsupervised algorithm like snaphu of MCF\nPixel-wise process\n\nEntender el problema\nDefinir Objetivos\nCrear Pipeline con imágenes\nCrear Esquema de tareas\nPreparar Glosario\nInvestigar de sobre los softwares\nVariables book (productos satelitales, softwares, etc)"
  },
  {
    "objectID": "softwares.html",
    "href": "softwares.html",
    "title": "Appendix B — Softwares",
    "section": "",
    "text": "InSAR softwares:\n\nSNAP\nGamma\nGMTSAR\nISCE\n\nTime series software:\n\nStaMPS\nPyRate\nMintPy\nLicSAR"
  },
  {
    "objectID": "softwares.html#insar-softwares",
    "href": "softwares.html#insar-softwares",
    "title": "Appendix B — Softwares",
    "section": "B.1 InSAR softwares",
    "text": "B.1 InSAR softwares\n\nSNAP:\n\nThe Sentinel Application Platform (SNAP) is a common architecture for all Sentinel Toolboxes. The software is developed by Brockmann Consult, Skywatch, Sensar and C-S. The SNAP architecture is ideal for Earth observation (EO) processing and analysis due to the following technological innovations: extensibility, portability, modular rich client platform, generic EO data abstraction, tiled memory management, and a graph processing framework. SNAP and the individual Sentinel Toolboxes support numerous sensors other than Sentinel sensors.\n\nGAMMA:\n\nThe GAMMA Software is a commercial software developed and maintained by GAMMA. We are dedicated to keep the software at a very advanced level. Through our R&D projects and the many contacts to highly competent SAR/InSAR/PSI specialists, we get valuable inputs to the software development activities. We regularly implement new functionality and adaptations to support new sensors and algorithms. Software licenses are in use world-wide supporting researchers, companies and public authorities in their daily work.\n\n\nThe GAMMA software supports the entire processing chain from Synthetic Aperture Radar (SAR) raw data to end products such as digital elevation models, displacement maps and land use maps. The GAMMA Software includes several Modules, each one consisting of documented, well structured code. The software is a toolbox providing a wide functionality to support the users in the setting up different processing tasks. Programs can be run individually on the command line or they can be called from scripts that permit running processing sequences in a more automated and efficient way.\nSoftware Modules:\n\nModular SAR Processor (MSP)\nInterferometry, Diff. Interferometry and Geocoding (ISP/DIFF&GEO)\nLand Application Tools (LAT)\nInterferometric Point Target Analysis (IPTA)\n\n\nGMTSAR:\n\nGMTSAR is an open source (GNU General Public License) InSAR processing system designed for users familiar with Generic Mapping Tools (GMT). The code is written in C and will compile on any computer where GMT and NETCDF are installed. The system has three main components:\n\n\n\na preprocessor for each satellite data type (ERS-1/2, Envisat, ALOS-1, TerraSAR-X, COSMOS-SkyMed, Radarsat-2, Sentinel-1A/B, and ALOS-2) to convert the native format and orbital information into a generic format;\nan InSAR processor to focus and align stacks of images, map topography into phase, and form the complex interferogram;\na postprocessor, mostly based on GMT, to filter the interferogram and construct interferometric products of phase, coherence, phase gradient, and line-of sight displacement in both radar and geographic coordinates;\n\nGMT is used to display all the products as pdf files and KML images for Google Earth. A set of shell scripts has been developed for standard 2-pass processing as well as geometric image alignment for stacking and time series. Users are welcome to contribute to this effort.\n\nISCE:\n\nThis is the Interferometric synthetic aperture radar Scientific Computing Environment (ISCE). Its initial development was funded by NASA’s Earth Science Technology Office (ESTO) under the Advanced Information Systems Technology (AIST) 2008 and is currently being funded under the NASA-ISRO SAR (NISAR) project.\n\n\nTHIS IS RESEARCH CODE PROVIDED TO YOU “AS IS” WITH NO WARRANTIES OF CORRECTNESS. USE AT YOUR OWN RISK.\nThis software is open source under the terms of the the Apache License. Its export classification is ‘EAR99 NLR’, which entails some restrictions and responsibilities. Please read the accompanying LICENSE.txt and LICENSE-2.0 files.\nISCE is a framework designed for the purpose of processing Interferometric Synthetic Aperture Radar (InSAR) data. The framework aspects of it have been designed as a general software development framework. It may have additional utility in a general sense for building other types of software packages. In its InSAR aspect ISCE supports data from many space-borne satellites and one air-borne platform. We continue to increase the number of sensors supported. At this time the sensors that are supported are the following: ALOS, ALOS2, COSMO_SKYMED, ENVISAT, ERS, KOMPSAT5, RADARSAT1, RADARSAT2, RISAT1, Sentinel1, TERRASARX, UAVSAR and SAOCOM1A."
  },
  {
    "objectID": "softwares.html#time-series-softwares",
    "href": "softwares.html#time-series-softwares",
    "title": "Appendix B — Softwares",
    "section": "B.2 Time series softwares",
    "text": "B.2 Time series softwares\n\nStaMPS:\n\nA software package to extract ground displacements from time series of synthetic aperture radar (SAR) acquisitions. The original version was developed at Stanford University but subsequent development has taken place at the University of Iceland, Delft University of Technology and the University of Leeds.The package incorporates persistent scatterer and small baseline methods plus an option to combine both approaches.\n\nPyRate:\n\nPyRate is a Python tool for estimating the average displacement rate (velocity) and cumulative displacement time-series of surface movements for every pixel in a stack of geocoded unwrapped interferograms generated by Interferometric Synthetic Aperture Radar (InSAR) processing. PyRate uses a “Small Baseline Subset” (SBAS) processing strategy and currently supports input data in the GAMMA or ROI_PAC software formats. Additionally, the European Space Agency SNAP software version 8 has a “PyRate export” capability that prepares SNAP output data in the GAMMA format for use with PyRate.\n\n\nThe PyRate project started in 2012 as a partial Python translation of “Pirate”, a Matlab tool developed by the University of Leeds and the Guangdong University of Technology.\nThe full PyRate documentation is available at http://geoscienceaustralia.github.io/PyRate\n\nMintPy:\n\nThe Miami INsar Time-series software in PYthon (MintPy as /mɪnt paɪ/) is an open-source package for Interferometric Synthetic Aperture Radar (InSAR) time series analysis. It reads the stack of interferograms (coregistered and unwrapped) in ISCE, ARIA, FRInGE, HyP3, GMTSAR, SNAP, GAMMA or ROI_PAC format, and produces three dimensional (2D in space and 1D in time) ground surface displacement in line-of-sight direction. It includes a routine time series analysis (smallbaselineApp.py) and some independent toolbox. This package was called PySAR before version 1.1.1. For version 1.1.2 and onward, we use MintPy instead. This is research code provided to you “as is” with NO WARRANTIES OF CORRECTNESS. Use at your own risk.\n\nLicSAR:\n\nFor each frame, the main LiCSAR outputs are stored in the ‘Products’ folder. As can be seen in Figure 1, all the generated interferometric pairs are located in the ‘Interferograms’ folder. The name of each interferometric pair shows the date of acquisitions in that pair. We are currently generating three interferograms per epoch. For the details of the LiCSAR methodology, the reader is referred to (Lazecký et al. 2020). In summary, once a new acquisition arrives, it is being logically decomposed into pre-defined burst units and registered in the LiCSInfo database that handles burst and frame definitions. Images including bursts that form a given frame are extracted and merged into frame images. These are coregistered towards a primary frame image (a master image) that was set during the initialization of a frame, beforehand. The coregistration process includes the spectral diversity and other necessary corrections. Once coregistered, the interferograms are formed by combining the new image with three chronologically previous ones. This way is suitable for interpretation and for further use of the interferograms in multitemporal InSAR processing methods based on small baselines strategy (e.g. NSBAS approach currently implemented into custom LiCSBAS chain (Morishita et al. 2020)). The interferogram unwrapping is performed using optimized SNAPHU approach. All the LiCSAR products are multilooked by factors of 5 in the range and 20 in the azimuth directions to achieve a resolution of around 100×100 m per pixel.\n\n\n\n\n\n\nLazecký, Milan, Karsten Spaans, Pablo J. González, Yasser Maghsoudi, Yu Morishita, Fabien Albino, John Elliott, et al. 2020. “LiCSAR: An Automatic InSAR Tool for Measuring and Monitoring Tectonic and Volcanic Activity.” Remote Sensing 12 (15): 2430. https://doi.org/10.3390/rs12152430.\n\n\nMorishita, Yu, Milan Lazecky, Tim Wright, Jonathan Weiss, John Elliott, and Andy Hooper. 2020. “LiCSBAS: An Open-Source InSAR Time Series Analysis Package Integrated with the LiCSAR Automated Sentinel-1 InSAR Processor.” Remote Sensing 12 (3): 424. https://doi.org/10.3390/rs12030424."
  },
  {
    "objectID": "pipeline.html",
    "href": "pipeline.html",
    "title": "4  Pipeline",
    "section": "",
    "text": "High level components of an InSAR processing pipeline\n\n\n\nData Access:\n\nNeed SLC products Source ASF, CopHub, etc.\n\nData organisation:\n\nDelivered S1 SLC scenes do not consistently have the same coverage. Either do further processing at the “burst” level, or form new scenes from sets of bursts). The latter approach was used at GA.\n\nCo-registration of reference SLC to DEM:\n\nThis mapping is used later for interferogram geocoding\n\nCo-registration of other SLCs to reference:\n\nThe co-registration of each S1 image needs to be better than 1/1000th of a pixel to avoid burst discontinuities. GA implemented a tree network structure to apply co-registrations and avoid propagating mis-registration in a large multi-year stack of 12 day images.\n\nInterferogram formation:\n\nTypically done with an “SBAS” network where every SAR image is used to form multiple interferograms for redundancy of information\n\nInterferogram unwrapping:\n\nConvert fringes to continuous phase field using unsupervised algorithm like snaphu of MCF. These are good for automation but they do make mistakes (unwrapping errors)\n\nGeocoding:\n\nConvert products (interferograms, coherence, backscatter) from radar to geographic geometry"
  },
  {
    "objectID": "glosario.html",
    "href": "glosario.html",
    "title": "Appendix A — Glosario",
    "section": "",
    "text": "ASF\nCopernicus Hub\nSLC\nS1\nGA\nSBAS Network"
  },
  {
    "objectID": "pipeline.html#time-series-processing",
    "href": "pipeline.html#time-series-processing",
    "title": "4  Pipeline",
    "section": "4.2 Time Series Processing",
    "text": "4.2 Time Series Processing\n\n4.2.1 Unwrapping check\nThrow out pixels that fail the check – removes unwrapping errors\n\n\n4.2.2 Orbital error removal\nModel long wavelength spatial trends and remove. Usually not that important for S1\n\n\n4.2.3 Atmospheric noise removal\nVarious approaches, best use external weather model data to generate a phase correction\n\n\n4.2.4 Network inversion for displacement time series\nPixel-wise process\n\n\n4.2.5 Network inversion for average displacement\nPixel-wise process for velocity"
  },
  {
    "objectID": "pipeline.html#processing-sar",
    "href": "pipeline.html#processing-sar",
    "title": "4  Pipeline",
    "section": "4.1 Processing SAR",
    "text": "4.1 Processing SAR\n\n4.1.1 Data Access\nNeed SLC products Source ASF, CopHub, etc.\n\n\n4.1.2 Data organisation\nDelivered S1 SLC scenes do not consistently have the same coverage. Either do further processing at the “burst” level, or form new scenes from sets of bursts). The latter approach was used at GA.\n\n\n4.1.3 Co-registration of reference SLC to DEM\nThis mapping is used later for interferogram geocoding\n\n\n4.1.4 Co-registration of other SLCs to reference\nThe co-registration of each S1 image needs to be better than 1/1000th of a pixel to avoid burst discontinuities. GA implemented a tree network structure to apply co-registrations and avoid propagating mis-registration in a large multi-year stack of 12 day images.\n\n\n4.1.5 Interferogram formation\nTypically done with an “SBAS” network where every SAR image is used to form multiple interferograms for redundancy of information\n\n\n4.1.6 Interferogram unwrapping\nConvert fringes to continuous phase field using unsupervised algorithm like snaphu of MCF. These are good for automation but they do make mistakes (unwrapping errors)\n\n\n4.1.7 Geocoding\nConvert products (interferograms, coherence, backscatter) from radar to geographic geometry"
  },
  {
    "objectID": "interf.html",
    "href": "interf.html",
    "title": "4  Interferometría",
    "section": "",
    "text": "https://prs.dgf.uchile.cl/observatorio-g-data/insar/\nA SAR signal contains amplitude and phase information. Amplitude is the strength of the radar response and phase is the fraction of one complete sine wave cycle (a single SAR wavelength). The phase of the SAR image is determined primarily by the distance between the satellite antenna and the ground targets.\nInterferometric SAR (InSAR) exploits the phase difference between two complex radar SAR observations of the same area, taken from slightly different sensor positions, and extracts distance information about the Earth’s terrain.\nBy combining the phase of these two images after coregistration, an interferogram can be generated where phase is highly correlated to the terrain topography and deformation patterns can be mapped. If the phase shift related to topography is removed from the interferograms, the difference between the resulting products will show surface deformation patterns occurred between the two acquisition dates. This methodology is called Differential Interferometry (DInSAR).\nThe following interferogram of Bam, Iran shows the terrain deformation following a M6.6 earthquake on December 26th 2003, which killed 26,271 people and injured an additional 30,000. The images were acquired from ENVISAT ASAR on December 3rd 2003 and February 11th 2004 with a baseline (spatial separation between satellite orbits) of 14 m. The coloured fringes map the deformation of the surface of the Earth in the direction of the view from the satellite in units of the radar wavelength (2.8 cm) between colour cycles.\nReferences\nhttps://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/product-overview/interferometry"
  }
]